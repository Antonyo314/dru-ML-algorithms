{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0,
     12,
     21,
     30
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(w, X):\n",
    "    \"\"\"\n",
    "    Returns a linear regression model prediction labels for objects in matrix \n",
    "    X using weights w:\n",
    "    y_pred = (X,w)\n",
    "    \"\"\"\n",
    "    if X.ndim == 1:\n",
    "        return(np.insert(X, 0, 1).dot(w))\n",
    "    else:\n",
    "        n = X.shape[0]\n",
    "        return np.dot(np.hstack((np.ones((n,1)),X)),w)\n",
    "    \n",
    "    \n",
    "def mean_squared_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Returns a mean squared error between real and predicted labels\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mse = np.sum((y - y_pred)**2) / y.size\n",
    "    return mse\n",
    "\n",
    "def mean_absolute_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Returns a mean absolute error between real and predicted labels\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mae = np.sum(abs(y - y_pred)) / y.size\n",
    "    return mae\n",
    "\n",
    "def cost_function(w, X, y, type_f='mse'):\n",
    "    \"\"\"\n",
    "    Returns a cost function of a linear model with coefficients w\n",
    "    oh features X and labels y.\n",
    "    \"\"\"\n",
    "    if (type_f == 'mae'):\n",
    "        return mean_absolute_error(y, linear_prediction(w, X))\n",
    "    elif (type_f == 'mse'):\n",
    "        return mean_squared_error(y, linear_prediction(w, X))\n",
    "    else:\n",
    "        #raise\n",
    "        print('error: incorrect type of function')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     37
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression_fit(X, y, minimize='grad_desc', cost_f='mse',\n",
    "                          w0=None, eta=1e-2):\n",
    "    \"\"\"\n",
    "    Returns weights that minimizes cost function.\n",
    "    \"\"\"   \n",
    "    if (minimize == 'analytical'):\n",
    "        # the cost function is 'mse' automatically\n",
    "        # X_t = X.transpose()\n",
    "        # w = np.linalg.inv(X_t.dot(X)).dot(X_t).dot(y)\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        w = np.linalg.lstsq(X,y)[0]\n",
    "        \n",
    "    elif (minimize == 'grad_desc'):\n",
    "        # the cost function is 'mse' automatically\n",
    "        if(w0 == None):\n",
    "            w0 = np.zeros(X.shape[1] + 1)\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        w = gradient_descent(X, y, w0, eta)[0]\n",
    "        w = w.reshape(w.shape[0])\n",
    "\n",
    "    elif (minimize == 'st_grad_desc'):\n",
    "        # the cost function is 'mse' automatically\n",
    "        if(w0 == None):\n",
    "            w0 = np.zeros(X.shape[1] + 1)\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        w = stochastic_gradient_descent(X, y, w0, eta)[0]\n",
    "        w = w.reshape(w.shape[0])\n",
    "    \n",
    "    elif (minimize == 'scipy_minimize'):\n",
    "        if(w0 == None):\n",
    "            w0 = np.zeros(X.shape[1] + 1)\n",
    "        w = scipy.optimize.minimize(lambda w: cost_function(w, X, y, cost_f), w0).x\n",
    "    else:\n",
    "        #raise\n",
    "        print('error: incorrect minimization method')\n",
    "        return\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_step(X, y, w, eta=0.01):\n",
    "    grad = 2 * X.T.dot(X.dot(w) - y) / X.shape[0] \n",
    "    w_next = w - eta * grad \n",
    "    return w_next\n",
    "\n",
    "def gradient_descent(X, y, w0=None, eta=1e-2,\n",
    "                     max_iter=1e4, min_weight_dist=1e-8):    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if(w0 == None):\n",
    "        w0 = np.zeros(X.shape[1])\n",
    "        \n",
    "    w = w0\n",
    "    weight_dist = np.inf\n",
    "    errors = []\n",
    "    iter_num = 0\n",
    "        \n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter: \n",
    "        w_next = gradient_step(X, y, w, eta)        \n",
    "        errors.append(mean_squared_error(y, X.dot(w_next)))\n",
    "        weight_dist = np.linalg.norm(w_next - w)      \n",
    "        w = w_next\n",
    "        iter_num += 1\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, k, eta=0.01):\n",
    "    grad = 2 * (X[k].dot(w) - y[k]) * X[k,:] / X.shape[0] \n",
    "    w_next = w - eta * grad   \n",
    "    return w_next\n",
    "\n",
    "def stochastic_gradient_descent(X, y, w0=None, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42):    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if(w0 == None):\n",
    "        w0 = np.zeros(X.shape[1])\n",
    "        \n",
    "    w = w0\n",
    "    weight_dist = np.inf\n",
    "    errors = []\n",
    "    iter_num = 0\n",
    "    #import random\n",
    "    #k = np.array(range(X.shape[0]))\n",
    "    #random.shuffle(k)\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:  \n",
    "        #print('\\nit.',iter_num)\n",
    "        #print('w: ',w)\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        #print('k: ',random_ind)\n",
    "        w_next = stochastic_gradient_step(X, y, w, random_ind, eta)     \n",
    "        errors.append(mean_squared_error(y, X.dot(w_next)))\n",
    "        weight_dist = np.linalg.norm(w_next - w)      \n",
    "        #print('d: ',weight_dist)\n",
    "        w = w_next\n",
    "        iter_num += 1\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate / Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X, mean_std=True):\n",
    "    if mean_std:\n",
    "        means, stds = X.mean(axis=0), X.std(axis=0)\n",
    "        X = (X - means) / stds\n",
    "    else:\n",
    "        minim, maxim = data.min(axis = 0), data.max(axis = 0)\n",
    "        X = (X - minim) / (maxim - minim)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "\n",
    "sample_size = 200\n",
    "data, target = datasets.make_regression(n_samples = sample_size,\n",
    "                                        n_features = 5, \n",
    "                                        n_informative = 4, \n",
    "                                        n_targets = 1, noise = 5.,\n",
    "                                        coef = False, random_state = 2)\n",
    "#data = normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('Data/weights_heights.csv', index_col='Index')\n",
    "data_frame = pd.read_csv('Data/advertising.csv')\n",
    "\n",
    "features = ['TV'] # , 'Radio','Newspaper']\n",
    "labels = ['Sales']\n",
    "data = np.array(data_frame[features].values, dtype=float)[:sample_size]\n",
    "target = np.array(data_frame[labels].values, dtype=float)[:sample_size]\n",
    "target = target.reshape(target.shape[0])\n",
    "\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train & test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "train_data, test_data, train_labels, test_labels = \\\n",
    "cross_validation.train_test_split(data, target, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: \n",
      " [[ 0.56266908  1.14485538 -0.15211769  0.82978905 -0.16451506]\n",
      " [-0.87810789  0.25657045 -0.98877905 -0.33882197 -0.15643417]\n",
      " [ 0.70201352  0.43198898 -1.01786273  0.28774717 -0.35613593]\n",
      " [-1.06492788  0.30752553 -1.36963867  2.67033724 -1.40084545]\n",
      " [ 1.42496703  0.52110943 -0.70819438  1.15553059 -0.4468579 ]] \n",
      "...\n",
      "\n",
      "train_labels: \n",
      " [ 118.35335449  -83.4536414    58.84383323 -184.41198763  133.15803617] ...\n"
     ]
    }
   ],
   "source": [
    "print('train_data: \\n',train_data[:5],'\\n...\\n')\n",
    "print('train_labels: \\n',train_labels[:5],'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_result(coef, true, predict, cut = 5):\n",
    "    print('w:\\n',coef,'\\n')\n",
    "    print('true vs. prediction:\\n',vstack((true,predict)).T[:cut],'\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_for_one_feature(train_data, train_labels, w, title):\n",
    "    x = np.linspace(train_data.min(), train_data.max(), 2).reshape((2,1))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.plot(train_data, train_labels, 'o', markersize = 3)\n",
    "    #print(x)\n",
    "    #print(linear_prediction(w, x))\n",
    "    plt.plot(x, linear_prediction(w,x), '-', linewidth = 4)\n",
    "    plt.xlabel('feature')\n",
    "    plt.ylabel('label')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical OLS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ -0.36559549  91.99673611  71.70021632  11.91772276   0.611216    73.8495751 ] \n",
      "\n",
      "true vs. prediction:\n",
      " [[  -2.99954166    1.39857714]\n",
      " [ 151.99687856  148.36137291]\n",
      " [ -21.3469044   -14.77390173]\n",
      " [ 210.32076737  209.62970353]\n",
      " [   9.77306619   14.58461328]] \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "w = linear_regression_fit(train_data, train_labels, minimize='analytical')\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical method using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ -0.36559551  91.99673611  71.70021629  11.91772272   0.61121599\n",
      "  73.84957509] \n",
      "\n",
      "true vs. prediction:\n",
      " [[  -2.99954166    1.39857717]\n",
      " [ 151.99687856  148.36137291]\n",
      " [ -21.3469044   -14.7739017 ]\n",
      " [ 210.32076737  209.62970353]\n",
      " [   9.77306619   14.58461335]] \n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yaroslava/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0])\n",
    "w = linear_regression_fit(train_data, train_labels,\n",
    "                          minimize='grad_desc', eta=0.1)\n",
    "\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical method using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yaroslava/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ -0.31638139  91.75245422  71.40564143  11.67582924   0.49480574\n",
      "  73.72921677] \n",
      "\n",
      "true vs. prediction:\n",
      " [[  -2.99954166    1.74852984]\n",
      " [ 151.99687856  148.27061492]\n",
      " [ -21.3469044   -14.31318066]\n",
      " [ 210.32076737  209.46375159]\n",
      " [   9.77306619   14.98328227]] \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0])\n",
    "w = linear_regression_fit(train_data, train_labels,\n",
    "                          minimize='st_grad_desc', eta=0.05)\n",
    "\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical method using scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ -0.60850538  91.53711828  71.42394879  12.31444398   0.35759316\n",
      "  73.47782498] \n",
      "\n",
      "true vs. prediction:\n",
      " [[  -2.99954166    0.97157278]\n",
      " [ 151.99687856  147.25743655]\n",
      " [ -21.3469044   -15.28496548]\n",
      " [ 210.32076737  207.68950867]\n",
      " [   9.77306619   13.15112739]] \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0])\n",
    "w = linear_regression_fit(train_data, train_labels, minimize='scipy_minimize', cost_f='mae')\n",
    "\n",
    "w.reshape((1,w.shape[0]))\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.linear_model.SGDRegression for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ -0.99235873  91.1684989   71.02926226  10.599685     0.23201854\n",
      "  73.214544  ] \n",
      "\n",
      "true vs. prediction:\n",
      " [[  -2.99954166    1.69176417]\n",
      " [ 151.99687856  147.53276654]\n",
      " [ -21.3469044   -14.0181392 ]\n",
      " [ 210.32076737  208.33176954]\n",
      " [   9.77306619   16.10693402]] \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model \n",
    "\n",
    "sgd_regressor = linear_model.SGDRegressor(random_state=None, n_iter=20)\n",
    "sgd_regressor.fit(train_data, train_labels)\n",
    "sgd_regressor.predict(test_data)\n",
    "w = [sgd_regressor.intercept_[0]]\n",
    "w.extend(sgd_regressor.coef_)\n",
    "w = np.array(w)\n",
    "print_result(w,test_labels,sgd_regressor.predict(test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
