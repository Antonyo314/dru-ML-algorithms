{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     12,
     21,
     30,
     44
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(w, X):\n",
    "    \"\"\"\n",
    "    Returns a linear regression model prediction labels for objects in matrix \n",
    "    X using weights w:\n",
    "    y_pred = (X,w)\n",
    "    \"\"\"\n",
    "    if X.ndim == 1:\n",
    "        return(np.insert(X, 0, 1).dot(w))\n",
    "    else:\n",
    "        n = X.shape[0]\n",
    "        return np.dot(np.hstack((np.ones((n,1)),X)),w)\n",
    "\n",
    "def mean_squared_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Returns a mean squared error between real and predicted labels\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mse = np.sum((y - y_pred)**2) / y.size\n",
    "    return mse\n",
    "\n",
    "def mean_absolute_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Returns a mean absolute error between real and predicted labels\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mae = np.sum(abs(y - y_pred)) / y.size\n",
    "    return mae\n",
    "\n",
    "def cost_function(w, X, y, type_f='mse'):\n",
    "    \"\"\"\n",
    "    Returns a cost function of a linear model with coefficients w\n",
    "    oh features X and labels y.\n",
    "    \"\"\"\n",
    "    if (type_f == 'mae'):\n",
    "        return mean_absolute_error(y, linear_prediction(w, X))\n",
    "    elif (type_f == 'mse'):\n",
    "        return mean_squared_error(y, linear_prediction(w, X))\n",
    "    else:\n",
    "        #raise\n",
    "        print('error: incorrect type of function')\n",
    "        return\n",
    "\n",
    "def linear_regression_fit(X, y, minimize='grad_desc', cost_f='mse',\n",
    "                          w0=None, eta=1e-2):\n",
    "    \"\"\"\n",
    "    Returns weights that minimizes cost function.\n",
    "    \"\"\"   \n",
    "    if (minimize == 'analytical'):\n",
    "        # the cost function is 'mse' automatically\n",
    "        # X_t = X.transpose()\n",
    "        # w = np.linalg.inv(X_t.dot(X)).dot(X_t).dot(y)\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        w = np.linalg.lstsq(X,y)[0]\n",
    "        \n",
    "    elif (minimize == 'grad_desc'):\n",
    "        # the cost function is 'mse' automatically\n",
    "        if(w0 == None):\n",
    "            w0 = np.zeros(X.shape[1] + 1)\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        w = gradient_descent(X, y, w0, eta)[0]\n",
    "        w = w.reshape(w.shape[0])\n",
    "\n",
    "    elif (minimize == 'st_grad_desc'):\n",
    "        # the cost function is 'mse' automatically\n",
    "        if(w0 == None):\n",
    "            w0 = np.zeros(X.shape[1] + 1)\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "        w = stochastic_gradient_descent(X, y, w0, eta)[0]\n",
    "        w = w.reshape(w.shape[0])\n",
    "    \n",
    "    elif (minimize == 'scipy_minimize'):\n",
    "        if(w0 == None):\n",
    "            w0 = np.zeros(X.shape[1] + 1)\n",
    "        w = scipy.optimize.minimize(lambda w: cost_function(w, X, y, cost_f), w0).x\n",
    "    else:\n",
    "        #raise\n",
    "        print('error: incorrect minimization method')\n",
    "        return\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     5
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_step(X, y, w, eta=0.01):\n",
    "    grad = 2 * X.T.dot(X.dot(w) - y) / X.shape[0] \n",
    "    w_next = w - eta * grad \n",
    "    return w_next\n",
    "\n",
    "def gradient_descent(X, y, w0=None, eta=1e-2,\n",
    "                     max_iter=1e4, min_weight_dist=1e-8):    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if(w0 == None):\n",
    "        w0 = np.zeros(X.shape[1])\n",
    "        \n",
    "    w = w0\n",
    "    weight_dist = np.inf\n",
    "    errors = []\n",
    "    iter_num = 0\n",
    "        \n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter: \n",
    "        w_next = gradient_step(X, y, w, eta)        \n",
    "        errors.append(mean_squared_error(y, X.dot(w_next)))\n",
    "        weight_dist = np.linalg.norm(w_next - w)      \n",
    "        w = w_next\n",
    "        iter_num += 1\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, k, eta=0.01):\n",
    "    grad = 2 * (X[k].dot(w) - y[k]) * X[k,:] / X.shape[0] \n",
    "    w_next = w - eta * grad   \n",
    "    return w_next\n",
    "\n",
    "def stochastic_gradient_descent(X, y, w0=None, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42):    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if(w0 == None):\n",
    "        w0 = np.zeros(X.shape[1])\n",
    "        \n",
    "    w = w0\n",
    "    weight_dist = np.inf\n",
    "    errors = []\n",
    "    iter_num = 0\n",
    "    #import random\n",
    "    #k = np.array(range(X.shape[0]))\n",
    "    #random.shuffle(k)\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:  \n",
    "        #print('\\nit.',iter_num)\n",
    "        #print('w: ',w)\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        w_next = stochastic_gradient_step(X, y, w, random_ind, eta)     \n",
    "        errors.append(mean_squared_error(y, X.dot(w_next)))\n",
    "        weight_dist = np.linalg.norm(w_next - w)      \n",
    "        #print('d: ',weight_dist)\n",
    "        w = w_next\n",
    "        iter_num += 1\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_result(coef, true, predict, cut = 5):\n",
    "    print('w:\\n',coef,'\\n')\n",
    "    print('true vs. prediction:\\n',vstack((true,predict)).T[:cut],'\\n...')\n",
    "    print('root mean squared error: ',round((mean_squared_error(true, predict))**.5,3))\n",
    "    print('mean absolute error: ',round(mean_absolute_error(true, predict),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_for_one_feature(train_data, train_labels, w, title):\n",
    "    x = np.linspace(train_data.min(), train_data.max(), 2).reshape((2,1))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.plot(train_data, train_labels, 'o', markersize = 3)\n",
    "    #print(x)\n",
    "    #print(linear_prediction(w, x))\n",
    "    plt.plot(x, linear_prediction(w,x), '-', linewidth = 4)\n",
    "    plt.xlabel('feature')\n",
    "    plt.ylabel('label')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X, mean_std=True):\n",
    "    if mean_std:\n",
    "        means, stds = X.mean(axis=0), X.std(axis=0)\n",
    "        X = (X - means) / stds\n",
    "    else:\n",
    "        minim, maxim = data.min(axis = 0), data.max(axis = 0)\n",
    "        X = (X - minim) / (maxim - minim)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "\n",
    "sample_size = 200\n",
    "data, target = datasets.make_regression(n_samples = sample_size,\n",
    "                                        n_features = 1, \n",
    "                                        n_informative = 1, \n",
    "                                        n_targets = 1, noise = 5.,\n",
    "                                        coef = False, random_state = 2)\n",
    "#data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \"Advertising\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('Data/weights_heights.csv', index_col='Index')\n",
    "data_frame = pd.read_csv('Data/advertising.csv')\n",
    "\n",
    "features = ['TV'] # , 'Radio','Newspaper']\n",
    "labels = ['Sales']\n",
    "data = np.array(data_frame[features].values, dtype=float)[:sample_size]\n",
    "target = np.array(data_frame[labels].values, dtype=float)[:sample_size]\n",
    "target = target.reshape(target.shape[0])\n",
    "\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy dataset \"Boston\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_boston()\n",
    "data = dataset.data\n",
    "target = dataset.target\n",
    "\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train & test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cross_val\n",
    "\n",
    "train_data, test_data, \\\n",
    "train_labels, test_labels = cross_val.train_test_split(data, target,\n",
    "                                                       test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: \n",
      " [[-0.41131277  0.370669   -1.13908197  3.66839786 -0.96572262  1.93805667\n",
      "  -0.67120228  0.67353024 -0.52300145 -1.14175084 -1.64394538  0.22362871\n",
      "  -1.35170466]\n",
      " [ 1.20159508 -0.48772236  1.01599907 -0.27259857  1.36749033 -0.10917784\n",
      "   0.93969163 -0.74768087  1.66124525  1.53092646  0.80657583 -2.80735852\n",
      "   0.35280855]\n",
      " [-0.4087034   1.4436582  -1.12303194 -0.27259857 -1.01668877  1.28271368\n",
      "  -1.05525646  0.36682207 -0.52300145 -0.06080135 -1.50523663  0.44105193\n",
      "  -1.01809105]\n",
      " [ 1.42828765 -0.48772236  1.01599907 -0.27259857  1.07378711 -0.55367135\n",
      "   0.95391585 -0.89628127  1.66124525  1.53092646  0.80657583 -3.82649563\n",
      "   1.64521083]\n",
      " [-0.41527165 -0.48772236 -0.59338101 -0.27259857 -0.74026221  1.28271368\n",
      "  -0.26581176  0.55715988 -0.8678825  -0.98732948 -0.30309415  0.39642699\n",
      "  -1.2087274 ]] \n",
      "...\n",
      "\n",
      "train_labels: \n",
      " [ 46.   11.7  34.9   8.3  34.7] ...\n"
     ]
    }
   ],
   "source": [
    "print('train_data: \\n',train_data[:5],'\\n...\\n')\n",
    "print('train_labels: \\n',train_labels[:5],'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical OLS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ 22.57736942  -1.07019499   1.12744822   0.42637639   0.98893845\n",
      "  -2.40167277   2.32130331   0.28282795  -3.02276273   2.74683679\n",
      "  -1.95728985  -2.13759197   0.71222598  -4.24109179] \n",
      "\n",
      "true vs. prediction:\n",
      " [[ 22.          27.35097951]\n",
      " [ 33.1         36.03764038]\n",
      " [ 13.1         13.89880413]\n",
      " [ 10.2         16.96233098]\n",
      " [ 22.6         22.53901274]] \n",
      "...\n",
      "root mean squared error:  4.56\n",
      "mean absolute error:  3.212\n"
     ]
    }
   ],
   "source": [
    "w = linear_regression_fit(train_data, train_labels, minimize='analytical')\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical method using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ 22.57736942  -1.07019496   1.12744816   0.42637617   0.98893849\n",
      "  -2.40167273   2.32130334   0.28282792  -3.02276275   2.74683632\n",
      "  -1.95728929  -2.13759195   0.71222598  -4.24109178] \n",
      "\n",
      "true vs. prediction:\n",
      " [[ 22.          27.35097968]\n",
      " [ 33.1         36.03764034]\n",
      " [ 13.1         13.89880416]\n",
      " [ 10.2         16.96233092]\n",
      " [ 22.6         22.53901263]] \n",
      "...\n",
      "root mean squared error:  4.56\n",
      "mean absolute error:  3.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yaroslava/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0])\n",
    "w = linear_regression_fit(train_data, train_labels,\n",
    "                          minimize='grad_desc', eta=0.1)\n",
    "\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical method using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yaroslava/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ 21.19789478  -0.79624476   0.62114708  -0.2896012    1.05979447\n",
      "  -0.93202343   2.90585565   0.09252742  -1.70105643   0.77158682\n",
      "  -0.23569507  -1.7022628    0.70661467  -3.82491748] \n",
      "\n",
      "true vs. prediction:\n",
      " [[ 22.          25.58828245]\n",
      " [ 33.1         33.721842  ]\n",
      " [ 13.1         13.97860023]\n",
      " [ 10.2         14.19202938]\n",
      " [ 22.6         20.4205968 ]] \n",
      "...\n",
      "root mean squared error:  4.747\n",
      "mean absolute error:  3.263\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0])\n",
    "w = linear_regression_fit(train_data, train_labels,\n",
    "                          minimize='st_grad_desc', eta=0.05)\n",
    "\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical method using scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [  2.15349679e+01  -1.09892182e+00   8.53421725e-01  -1.81436615e-02\n",
      "   6.36572140e-01  -1.22434918e+00   3.39019761e+00  -5.95183833e-01\n",
      "  -2.24866774e+00   7.32604822e-01  -1.11920817e+00  -1.61433179e+00\n",
      "   1.02423587e+00  -2.56595273e+00] \n",
      "\n",
      "true vs. prediction:\n",
      " [[ 22.          26.12351727]\n",
      " [ 33.1         33.52743653]\n",
      " [ 13.1         12.68632006]\n",
      " [ 10.2         12.83731336]\n",
      " [ 22.6         22.39157661]] \n",
      "...\n",
      "root mean squared error:  4.519\n",
      "mean absolute error:  3.059\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0])\n",
    "w = linear_regression_fit(train_data, train_labels, minimize='scipy_minimize', cost_f='mae')\n",
    "\n",
    "w.reshape((1,w.shape[0]))\n",
    "print_result(w,test_labels,linear_prediction(w, test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.linear_model.SGDRegression for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      " [ 22.56726849  -0.95383693   0.91802972  -0.12115878   1.0346265\n",
      "  -1.83453645   2.51933885   0.09100584  -2.62777259   1.43343082\n",
      "  -0.68943404  -2.02193895   0.74196382  -4.16509828] \n",
      "\n",
      "true vs. prediction:\n",
      " [[ 22.          27.57196946]\n",
      " [ 33.1         35.92488147]\n",
      " [ 13.1         14.38865318]\n",
      " [ 10.2         16.11965381]\n",
      " [ 22.6         22.37793286]] \n",
      "...\n",
      "root mean squared error:  4.562\n",
      "mean absolute error:  3.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yaroslava/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model \n",
    "\n",
    "sgd_regressor = linear_model.SGDRegressor(random_state=None, n_iter=20)\n",
    "sgd_regressor.fit(train_data, train_labels)\n",
    "sgd_regressor.predict(test_data)\n",
    "w = [sgd_regressor.intercept_[0]]\n",
    "w.extend(sgd_regressor.coef_)\n",
    "w = np.array(w)\n",
    "print_result(w,test_labels,sgd_regressor.predict(test_data))\n",
    "if train_data.shape[1] == 1:\n",
    "    #plot_for_one_feature(train_data, train_labels, w, 'train')\n",
    "    plot_for_one_feature(test_data, test_labels, w, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
